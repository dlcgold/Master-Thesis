@article{pangenome,
	title        = {Computational graph pangenomics: a tutorial on data structures and their applications},
	author       = {Baaijens, Jasmijn A. and Bonizzoni, Paola and Boucher, Christina and Della Vedova, Gianluca and Pirola, Yuri and Rizzi, Raffaella and Sir{\'e}n, Jouni},
	year         = 2022,
	month        = {Mar},
	day          = {01},
	journal      = {Natural Computing},
	volume       = 21,
	number       = 1,
	pages        = {81--108},
	doi          = {10.1007/s11047-022-09882-6},
	issn         = {1572-9796},
	url          = {https://doi.org/10.1007/s11047-022-09882-6},
	abstract     = {Computational pangenomics is an emerging research field that is changing the way computer scientists are facing challenges in biological sequence analysis. In past decades, contributions from combinatorics, stringology, graph theory and data structures were essential in the development of a plethora of software tools for the analysis of the human genome. These tools allowed computational biologists to approach ambitious projects at population scale, such as the 1000 Genomes Project. A major contribution of the 1000 Genomes Project is the characterization of a broad spectrum of genetic variations in the human genome, including the discovery of novel variations in the South Asian, African and European populations---thus enhancing the catalogue of variability within the reference genome. Currently, the need to take into account the high variability in population genomes as well as the specificity of an individual genome in a personalized approach to medicine is rapidly pushing the abandonment of the traditional paradigm of using a single reference genome. A graph-based representation of multiple genomes, or a graph pangenome, is replacing the linear reference genome. This means completely rethinking well-established procedures to analyze, store, and access information from genome representations. Properly addressing these challenges is crucial to face the computational tasks of ambitious healthcare projects aiming to characterize human diversity by sequencing 1M individuals (Stark et al. 2019). This tutorial aims to introduce readers to the most recent advances in the theory of data structures for the representation of graph pangenomes. We discuss efficient representations of haplotypes and the variability of genotypes in graph pangenomes, and highlight applications in solving computational problems in human and microbial (viral) pangenomes.}
}
@article{pancon,
	title        = {Computational pan-genomics: status, promises and challenges},
	author       = {{The Computational Pan-Genomics Consortium}},
	year         = 2016,
	month        = 10,
	journal      = {Briefings in Bioinformatics},
	volume       = 19,
	number       = 1,
	pages        = {118--135},
	doi          = {10.1093/bib/bbw089},
	issn         = {1477-4054},
	url          = {https://doi.org/10.1093/bib/bbw089},
	abstract     = {{Many disciplines, from human genetics and oncology to plant breeding, microbiology and virology, commonly face the challenge of analyzing rapidly increasing numbers of genomes. In case of Homo sapiens, the number of sequenced genomes will approach hundreds of thousands in the next few years. Simply scaling up established bioinformatics pipelines will not be sufficient for leveraging the full potential of such rich genomic data sets. Instead, novel, qualitatively different computational methods and paradigms are needed. We will witness the rapid extension of computational pan-genomics, a new sub-area of research in computational biology. In this article, we generalize existing definitions and understand a pan-genome as any collection of genomic sequences to be analyzed jointly or to be used as a reference. We examine already available approaches to construct and use pan-genomes, discuss the potential benefits of future technologies and methodologies and review open challenges from the vantage point of the above-mentioned biological disciplines. As a prominent example for a computational paradigm shift, we particularly highlight the transition from the representation of reference genomes as strings to representations as graphs. We outline how this and other challenges from different application domains translate into common computational problems, point out relevant bioinformatics techniques and identify open problems in computer science. With this review, we aim to increase awareness that a joint approach to computational pan-genomics can help address many of the problems currently faced in various domains.}},
	eprint       = {https://academic.oup.com/bib/article-pdf/19/1/118/25406834/bbw089.pdf}
}
@article{moni,
	title        = {MONI: A Pangenomic Index for Finding Maximal Exact Matches},
	author       = {Rossi, Massimiliano and Oliva, Marco and Langmead, Ben and Gagie, Travis and Boucher, Christina},
	year         = 2022,
	month        = {02},
	journal      = {Journal of Computational Biology},
	publisher    = {Mary Ann Liebert, Inc., publishers 140 Huguenot Street, 3rd Floor New}
}
@inproceedings{phoni,
	title        = {PHONI: Streamed matching statistics with multi-genome references},
	author       = {Boucher, Christina and Gagie, Travis and Tomohiro, I and K{\"o}ppl, Dominik and Langmead, Ben and Manzini, Giovanni and Navarro, Gonzalo and Pacheco, Alejandro and Rossi, Massimiliano},
	year         = 2021,
	booktitle    = {2021 Data Compression Conference (DCC)},
	pages        = {193--202},
	organization = {IEEE}
}
@article{pbwt_durbin,
	title        = {Efficient haplotype matching and storage using the positional Burrows–Wheeler transform (PBWT)},
	author       = {Durbin, Richard},
	year         = 2014,
	month        = {01},
	journal      = {Bioinformatics},
	volume       = 30,
	number       = 9,
	pages        = {1266--1272},
	doi          = {10.1093/bioinformatics/btu014},
	issn         = {1367-4803},
	url          = {https://doi.org/10.1093/bioinformatics/btu014},
	abstract     = {Motivation: Over the last few years, methods based on suffix arrays using the Burrows–Wheeler Transform have been widely used for DNA sequence read matching and assembly. These provide very fast search algorithms, linear in the search pattern size, on a highly compressible representation of the dataset being searched. Meanwhile, algorithmic development for genotype data has concentrated on statistical methods for phasing and imputation, based on probabilistic matching to hidden Markov model representations of the reference data, which while powerful are much less computationally efficient. Here a theory of haplotype matching using suffix array ideas is developed, which should scale too much larger datasets than those currently handled by genotype algorithms.Results: Given M sequences with N bi-allelic variable sites, an O(NM) algorithm to derive a representation of the data based on positional prefix arrays is given, which is termed the positional Burrows–Wheeler transform (PBWT). On large datasets this compresses with run-length encoding by more than a factor of a hundred smaller than using gzip on the raw data. Using this representation a method is given to find all maximal haplotype matches within the set in O(NM) time rather than O(NM2) as expected from naive pairwise comparison, and also a fast algorithm, empirically independent of M given sufficient memory for indexes, to find maximal matches between a new sequence and the set. The discussion includes some proposals about how these approaches could be used for imputation and phasing.Availability:http://github.com/richarddurbin/pbwtContact:richard.durbin@sanger.ac.uk},
	eprint       = {https://academic.oup.com/bioinformatics/article-pdf/30/9/1266/647197/btu014.pdf}
}
@article{impute5,
	title        = {Genotype imputation using the Positional Burrows Wheeler Transform},
	author       = {Rubinacci, Simone and Delaneau, Olivier and Marchini, Jonathan},
	year         = 2020,
	month        = {11},
	day          = 16,
	journal      = {PLOS Genetics},
	publisher    = {Public Library of Science},
	volume       = 16,
	number       = 11,
	pages        = {e1009049},
	doi          = {10.1371/journal.pgen.1009049},
	url          = {https://doi.org/10.1371/journal.pgen.1009049},
	abstract     = {Author summary Genome-wide association studies (GWAS) typically use microarray technology to measure genotypes at several hundred thousand positions in the genome. However reference panels of genetic variation consist of haplotype data at >100 fold more positions in the genome. Genotype imputation makes genotype predictions at all the reference panel sites using the GWAS data. Reference panels are continuing to grow in size and this improves accuracy of the predictions, however methods need to be able to scale this increased size. We have developed a new version of the popular IMPUTE software than can handle reference panels with millions of haplotypes, and has better performance than other published approaches. A notable property of the new method is that it scales sub-linearly with reference panel size. Keeping the number of imputed markers constant, a 100 fold increase in reference panel size requires less than twice the computation time.}
}
