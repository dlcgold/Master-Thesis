@article{fmindex,
	title        = {Indexing compressed text},
	author       = {Ferragina, Paolo and Manzini, Giovanni},
	year         = 2005,
	journal      = {Journal of the ACM (JACM)},
	publisher    = {ACM New York, NY, USA},
	volume       = 52,
	number       = 4,
	pages        = {552--581}
}
@article{pangenome,
	title        = {Computational graph pangenomics: a tutorial on data structures and their applications},
	author       = {Baaijens, Jasmijn A. and Bonizzoni, Paola and Boucher, Christina and Della Vedova, Gianluca and Pirola, Yuri and Rizzi, Raffaella and Sir{\'e}n, Jouni},
	year         = 2022,
	month        = {Mar},
	day          = {01},
	journal      = {Natural Computing},
	volume       = 21,
	number       = 1,
	pages        = {81--108},
	doi          = {10.1007/s11047-022-09882-6},
	issn         = {1572-9796},
	url          = {https://doi.org/10.1007/s11047-022-09882-6},
	abstract     = {Computational pangenomics is an emerging research field that is changing the way computer scientists are facing challenges in biological sequence analysis. In past decades, contributions from combinatorics, stringology, graph theory and data structures were essential in the development of a plethora of software tools for the analysis of the human genome. These tools allowed computational biologists to approach ambitious projects at population scale, such as the 1000 Genomes Project. A major contribution of the 1000 Genomes Project is the characterization of a broad spectrum of genetic variations in the human genome, including the discovery of novel variations in the South Asian, African and European populations---thus enhancing the catalogue of variability within the reference genome. Currently, the need to take into account the high variability in population genomes as well as the specificity of an individual genome in a personalized approach to medicine is rapidly pushing the abandonment of the traditional paradigm of using a single reference genome. A graph-based representation of multiple genomes, or a graph pangenome, is replacing the linear reference genome. This means completely rethinking well-established procedures to analyze, store, and access information from genome representations. Properly addressing these challenges is crucial to face the computational tasks of ambitious healthcare projects aiming to characterize human diversity by sequencing 1M individuals (Stark et al. 2019). This tutorial aims to introduce readers to the most recent advances in the theory of data structures for the representation of graph pangenomes. We discuss efficient representations of haplotypes and the variability of genotypes in graph pangenomes, and highlight applications in solving computational problems in human and microbial (viral) pangenomes.}
}
@article{pbwt_durbin,
	title        = {{Efficient haplotype matching and storage using the positional Burrows–Wheeler transform (PBWT)}},
	author       = {Durbin, Richard},
	year         = 2014,
	month        = {01},
	journal      = {Bioinformatics},
	volume       = 30,
	number       = 9,
	pages        = {1266--1272},
	doi          = {10.1093/bioinformatics/btu014},
	issn         = {1367-4803},
	url          = {https://doi.org/10.1093/bioinformatics/btu014},
	abstract     = {{Motivation: Over the last few years, methods based on suffix arrays using the Burrows–Wheeler Transform have been widely used for DNA sequence read matching and assembly. These provide very fast search algorithms, linear in the search pattern size, on a highly compressible representation of the dataset being searched. Meanwhile, algorithmic development for genotype data has concentrated on statistical methods for phasing and imputation, based on probabilistic matching to hidden Markov model representations of the reference data, which while powerful are much less computationally efficient. Here a theory of haplotype matching using suffix array ideas is developed, which should scale too much larger datasets than those currently handled by genotype algorithms.Results: Given M sequences with N bi-allelic variable sites, an O(NM) algorithm to derive a representation of the data based on positional prefix arrays is given, which is termed the positional Burrows–Wheeler transform (PBWT). On large datasets this compresses with run-length encoding by more than a factor of a hundred smaller than using gzip on the raw data. Using this representation a method is given to find all maximal haplotype matches within the set in O(NM) time rather than O(NM2) as expected from naive pairwise comparison, and also a fast algorithm, empirically independent of M given sufficient memory for indexes, to find maximal matches between a new sequence and the set. The discussion includes some proposals about how these approaches could be used for imputation and phasing.Availability:http://github.com/richarddurbin/pbwtContact:richard.durbin@sanger.ac.uk}},
	eprint       = {https://academic.oup.com/bioinformatics/article-pdf/30/9/1266/647197/btu014.pdf}
}
@article{mpbwt,
	title        = {Multi-allelic positional Burrows-Wheeler transform},
	author       = {Naseri, Ardalan and Zhi, Degui and Zhang, Shaojie},
	year         = 2019,
	journal      = {BMC bioinformatics},
	publisher    = {BioMed Central},
	volume       = 20,
	number       = 11,
	pages        = {1--8}
}
@article{moni,
	title        = {MONI: a pangenomics index for finding MEMs},
	author       = {Rossi, Massimiliano and Oliva, Marco and Langmead, Ben and Gagie, Travis and Boucher, Christina},
	year         = 2021,
	journal      = {bioRxiv},
	publisher    = {Cold Spring Harbor Laboratory}
}
@inproceedings{phoni,
	title        = {PHONI: Streamed matching statistics with multi-genome references},
	author       = {Boucher, Christina and Gagie, Travis and Tomohiro, I and K{\"o}ppl, Dominik and Langmead, Ben and Manzini, Giovanni and Navarro, Gonzalo and Pacheco, Alejandro and Rossi, Massimiliano},
	year         = 2021,
	booktitle    = {2021 Data Compression Conference (DCC)},
	pages        = {193--202},
	organization = {IEEE}
}

@inproceedings{sdsl,
	title        = {From Theory to Practice: Plug and Play with Succinct Data Structures},
	author       = {Gog, Simon and Beller, Timo and Moffat, Alistair and Petri, Matthias},
	year         = 2014,
	booktitle    = {13th International Symposium on Experimental Algorithms, (SEA 2014)},
	pages        = {326--337},
	ee           = {http://dx.doi.org/10.1007/978-3-319-07959-2_28}
}

@article{bwt,
	title        = {A block-sorting lossless data compression algorithm},
	author       = {Burrows, Michael and Wheeler, David},
	year         = 1994,
	booktitle    = {Digital SRC Research Report},
	organization = {Citeseer}
}

@inproceedings{rlbwt,
	title        = {Succinct suffix arrays based on run-length encoding},
	author       = {M{\"a}kinen, Veli and Navarro, Gonzalo},
	year         = 2005,
	booktitle    = {Annual Symposium on Combinatorial Pattern Matching},
	pages        = {45--56},
	organization = {Springer}
}

@article{rindex,
	title        = {A fast and small subsampled r-index},
	author       = {Cobas, Dustin and Gagie, Travis and Navarro, Gonzalo},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2103.15329}
}

@article{lce,
	title        = {The longest common extension problem revisited and applications to approximate string searching},
	author       = {Ilie, Lucian and Navarro, Gonzalo and Tinta, Liviu},
	year         = 2010,
	journal      = {Journal of Discrete Algorithms},
	publisher    = {Elsevier},
	volume       = 8,
	number       = 4,
	pages        = {418--428}
}

@inproceedings{slp,
	title        = {Practical random access to SLP-compressed texts},
	author       = {Gagie, Travis and Manzini, Giovanni and Navarro, Gonzalo and Sakamoto, Hiroshi and Seelbach Benkner, Louisa and Takabatake, Yoshimasa and others},
	year         = 2020,
	booktitle    = {International Symposium on String Processing and Information Retrieval},
	pages        = {221--231},
	organization = {Springer}
}

@article{dpbwt,
	title        = {{d-PBWT: dynamic positional Burrows–Wheeler transform}},
	author       = {Sanaullah, Ahsan and Zhi, Degui and Zhang, Shaojie},
	year         = 2021,
	month        = {02},
	journal      = {Bioinformatics},
	volume       = 37,
	number       = 16,
	pages        = {2390--2397},
	doi          = {10.1093/bioinformatics/btab117},
	issn         = {1367-4803},
	url          = {https://doi.org/10.1093/bioinformatics/btab117},
	abstract     = {{Durbin’s positional Burrows–Wheeler transform (PBWT) is a scalable data structure for haplotype matching. It has been successfully applied to identical by descent (IBD) segment identification and genotype imputation. Once the PBWT of a haplotype panel is constructed, it supports efficient retrieval of all shared long segments among all individuals (long matches) and efficient query between an external haplotype and the panel. However, the standard PBWT is an array-based static data structure and does not support dynamic updates of the panel.Here, we generalize the static PBWT to a dynamic data structure, d-PBWT, where the reverse prefix sorting at each position is stored with linked lists. We also developed efficient algorithms for insertion and deletion of individual haplotypes. In addition, we verified that d-PBWT can support all algorithms of PBWT. In doing so, we systematically investigated variations of set maximal match and long match query algorithms: while they all have average case time complexity independent of database size, they have different worst case complexities and dependencies on additional data structures.The benchmarking code is available at genome.ucf.edu/d-PBWT.Supplementary data are available at Bioinformatics online.}},
	eprint       = {https://academic.oup.com/bioinformatics/article-pdf/37/16/2390/39947158/btab117.pdf}
}

@article{impute5,
	title        = {Genotype imputation using the Positional Burrows Wheeler Transform},
	author       = {Rubinacci, Simone and Delaneau, Olivier and Marchini, Jonathan},
	year         = 2020,
	month        = {Nov},
	day          = 16,
	journal      = {PLOS Genetics},
	publisher    = {Public Library of Science},
	volume       = 16,
	number       = 11,
	pages        = {e1009049},
	doi          = {10.1371/journal.pgen.1009049},
	url          = {https://doi.org/10.1371/journal.pgen.1009049},
	abstract     = {Author summary Genome-wide association studies (GWAS) typically use microarray technology to measure genotypes at several hundred thousand positions in the genome. However reference panels of genetic variation consist of haplotype data at >100 fold more positions in the genome. Genotype imputation makes genotype predictions at all the reference panel sites using the GWAS data. Reference panels are continuing to grow in size and this improves accuracy of the predictions, however methods need to be able to scale this increased size. We have developed a new version of the popular IMPUTE software than can handle reference panels with millions of haplotypes, and has better performance than other published approaches. A notable property of the new method is that it scales sub-linearly with reference panel size. Keeping the number of imputed markers constant, a 100 fold increase in reference panel size requires less than twice the computation time.}
}
