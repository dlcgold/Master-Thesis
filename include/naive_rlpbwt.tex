\section{RLPBWT na\"{i}ve}
\label{secrlpbwtna\"{i}ve}
Un primo approccio alla \textbf{compressione run-length} è stato quello di
semplicemente ``adattare'' quanto presentato da Durbin. Soprattutto a causa di
questo fattore tale approccio è stato nominato \textbf{RLPBWT na\"{i}ve}.\\
L'idea è stata quella di capire quali informazioni fossero necessarie al fine di
poter calcolare i match. Si è quindi partiti studiando quanto memorizzato da
Durbin stesso, pensando ad eventuali alternative.\\
Il dato fondamentale che la \textit{PBWT} tiene in memoria è \textit{il pannello
  $X$, con random access}. Ovviamente memorizzare l'intero pannello non era
possibile. D'altro canto l'idea dietro la 
\textbf{RLPBWT} è quella di memorizzare con \textit{compressione run-length}
la \textit{matrice PBWT}. La soluzione iniziale è stata quindi quella di
memorizzare gli indici delle \textit{teste di run}, ovvero gli indici iniziali
di ogni run. Ovviamente questa informazione non è sufficiente per poter sapere
se una run sia composta da simboli $\sigma=0$ o simboli
$\sigma=1$. Fortunatamente, essendo lo studio limitato, come per la
\textit{PBWT}, a pannelli costruiti su alfabeto binario, $\Sigma=\{0,1\}$, si è
potuto sfruttare il fatto che le run si alternano tra un carattere e
l'altro. Basta quindi tenere in memoria anche un valore booleano, nominato
$start^k$, che permetta di 
capire se, in colonna $k$, la prima run sia una run di simboli
$\sigma=0$. Infatti le run di 
indice pari presentano lo stesso simbolo della prima run e quindi, dato un
qualsiasi indice di run, è possibile sapere quale sia il simbolo di tale run.\\
Si memorizzano gli indici delle teste di run in un array $p_k$, di lunghezza
parti al numero di run in colonna $k$. Si riconoscono alcune delle informazioni
viste per la ``bozza'' di \textit{RLPBWT} vista alla sottosezione
\ref{subsectravis}.\\ 
Il passaggio successivo è stato quello di capire se le informazioni necessarie
al mapping fossero tutte necessarie. In altri termini se, data la colonna $k$
nella \textit{matrice PBWT}, fossero necessari $c[k]$, $u_k$ e $v_k$. In merito
al valore $c[k]$, per quanto calcolabile in tempo $\mathcal{O}(r)$, dove $r$ è
il numero di run della colonna $k$-esima, si è deciso che si potesse calcolarlo
in fase di costruzione delle \textit{RLPBWT} e memorizzarlo esattamente come per
la \textit{PBWT}. In merito invece ai vettori $u_k$ e $v_k$ si è cercato un modo
per ottenerne una rappresentazione che implicasse avere un solo valore per ogni
run della colonna. In altri termini si è cercato di capire se fosse possibile
tenere in memoria $r$ valori che permettessero di effettuare comunque il
mapping, a partire da un indice arbitrario $i\in\{0,\ldots,N-1\}$. Anche in
questo caso l'alternanza data dal caso binario ha permesso di trovare una
semplice soluzione. I valori di $u_k$ e $v_k$ crescono infatti in modo
alternato. A seconda del simbolo $\sigma$ rappresentato in una data run infatti
si avrà che solo i valori dell'array relativo a tale simbolo, nel range di
indici di quella run, verranno incrementati ad ogni passo di una unità. Per fare
un semplice esempio, se siamo in una run di 0 e iteriamo virtualmente
all'interno di tale run, solo i valori di $u_k$, in quel
range di indici, cresceranno di volta in volta di uno mentre per $v_k$, nello
stesso range, si avrà sempre lo stesso valore.
\begin{esempio}
  Si vede un esempio per chiarire meglio quanto espresso in merito a $u_k$ e
  $v_k$.\\
  Sia data la seguente colonna:
  \[y^5=00101111000000000000\]
  Si hanno, oltre a $c[5]=15$:
  \begin{table}[H]
    \footnotesize
    \centering
    \begin{tabular}{c||cc|c|c|cccc|cccccccccccc}
      & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 & 16
      & 17 & 18 & 19\\
      \hline
      \hline
      $y^5$ & 0 & 0 & 1 & 0 & 1 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0
      & 0 & 0 & 0\\
      \hline
      \hline
      $u_5$ & 0 & 1 & 2 & 2 & 3 & 3 & 3 & 3 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10
      & 11 & 12 & 13 & 14\\
      \hline
      $v_5$ & 0 & 0 & 0 & 1 & 1 & 2 & 3 & 4 & 5 & 5 & 5 & 5 & 5 & 5 & 5 & 5 & 5
      & 5 & 5 & 5
    \end{tabular}
  \end{table}
\end{esempio}
Grazie a questa alternanza è quindi possibile memorizzare, per ogni indice di
testa di run $i$, tale che $i\neq 0$, solo il valore di $u_k[i]$ o $v_k[i]$,
rispettivamente se sia una run su simboli $\sigma=1$ o $\sigma=0$. Questo in
quanto, se si analizza una run di zeri si avrà che solo i valori di $v_k$, nel
range della run, verranno incrementati ad ogni step. Per $i=0$ banalmente si ha
che $u_k[i]=v_k[i]=0$.\\
Memorizzando i valori di $u_k$ e $v_k$ in un array $uv_k$, tale che
$|uv_k|=|r|$, dove $r$ è il numero di run alla colonna $k$-esima, e dato
$i\in\{0,\ldots, r-1\}$, a seconda che la colonna presenti o meno la prima run
con simboli $\sigma=0$, si possono estrarre, in tempo costante, i valori di
$u_k$ e $v_k$ per una data testa di run. Nel dettaglio, dato $i\in{0,\ldots,
  r-1}$:
\begin{itemize}
  \item se $i=0$ si ha che $u_k[p[i]]=v_k[p[i]]=uv_k[0]=0$
  \item se $i\mod 2 =0$ si hanno due casi:
  \begin{itemize}
    \item la prima run è di simboli $\sigma=0$ e quindi si ottiene
    $u_k[p[i]]=uv_k[i-1]$ e $v_k[p[i]]=uv_k[i]$
    \item la prima run è di simboli $\sigma=1$ e quindi si ottiene
    $u_k[p[i]]=uv_k[i]$ e $v_k[p[i]]=uv_k[i-1]$
  \end{itemize}
  \item se $i\mod 2 \neq 0$ si hanno due casi:
  \begin{itemize}
    \item la prima run è di simboli $\sigma=0$ e quindi si ottiene
    $u_k[p[i]]=uv_k[i]$ e $v_k[p[i]]=uv_k[i-1]$
    \item la prima run è di simboli $\sigma=1$ e quindi si ottiene
    $u_k[p[i]]=uv_k[i-1]$ e $v_k[p[i]]=uv_k[i]$   
  \end{itemize}
\end{itemize}
Lo pseudocodice relativo a quanto appena detto è consultabile all'algoritmo
\ref{algo:uvnaive}.\\
In questa prima soluzione, infine, si è deciso di non mantenere in memoria il
\textit{prefix array} e di mantenere completamente il \textit{divergence
  array}, sotto forma di \textit{LCP array}, per poter, da un punto di vista
informale, reimplementare l'algoritmo 
5 di Durbin solo con meno informazioni in memoria. Il non memorizzare il
\textit{prefix array}, d'altro canto, impedisce di identificare con precisione
le righe del pannello per cui si ha un match quindi l'algoritmo, che verrà
presentato più avanti nella tesi, è limitato al poter sapere quante righe
matchano e non quali.\\
\textbf{INSERIRE ALGORITMO DI COSTRUZIONE}\\
In conclusione si riporta quindi un esempio dei dati memorizzati, per una data
colonna, nella \textit{RLPBWT na\"{i}ve}.
\begin{esempio}
  Sia data la seguente colonna:
  \[y^5=00101111000000000000\]
  Per la \textit{RLPBWT na\"{i}ve} si hanno in memoria:
  \[p_5=[0,2,3,4,8]\]
  \[uv_5=[0,2,1,3,5]\]
  \[c[5]=15\]
  \[l_5=[0,5,4,1,3,5,5,5,5,5,5,0,5,5,5,2,5,1,5,5]\]
\end{esempio}
\textbf{QUI MANCA SPEIGAZIONE OFFSET}\\
Si ha quindi già una forte riduzione dello spazio in memoria occupato dalla
struttura, questo nonostante la memorizzazione completa dell\textit{LCP array}.
Riprendendo quindi l'esempio già visto per la \textit{PBWT}, dato un panello di
medie dimensioni, con $N = 30000$ e$ M = 100000$, si ha che l'uso della
\textit{RLPBWT na\"{i}ve} richiede $\sim 8.17$ gigabytes di memoria (rispetto ai
$\sim 40.76$ gigabytes della \textit{PBWT}).\\
\textit{La spiegazione dell'algoritmo di match è rimandata a dopo l'introduzione
  della seconda variante, ovvero della \textbf{RLPBWT con bitvector}, in quanto
  le due versioni condividono, ad un alto livello di astrazione, il medesimo
  procedimento per il calcolo dei match.}