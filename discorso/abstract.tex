\documentclass[a4paper,11pt, oneside,italian]{article}

\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{framed}
\usepackage{xcolor}
\usepackage{amsmath}
\usepackage{enumitem}
\usepackage{relsize}
\usepackage{microtype}
\usepackage{typearea}
\newtheorem{teorema}{Teorema}
\newtheorem{definizione}{Definizione}
\newtheorem{esempio}{Esempio}
\newtheorem{corollario}{Corollario}
\newtheorem{lemma}{Lemma}
\newtheorem{osservazione}{Osservazione}
\newtheorem{nota}{Nota}
\newtheorem{esercizio}{Esercizio}
\hypersetup{
  pdftitle = {Algoritmi per la trasformata di Burrows--Wheeler posizionale con
    compressione run-length}, 
  pdfauthor = {Davide Cozzi},
  pdfsubject = {Discorso },
  pdfpagemode = UseNone
}


\usepackage{fancyhdr}
% \pagestyle{fancy}
% \fancyhead[LE,RO]{\slshape \rightmark}
% \fancyhead[LO,RE]{\slshape \leftmark}
\fancyfoot[C]{\thepage}

\title{Algoritmi per la trasformata di Burrows--Wheeler
  posizionale con compressione run-length} 
\author{Davide Cozzi\\\smaller matr.~829827}
\date{}
\makeatletter
\renewcommand{\paragraph}{%
  \@startsection{paragraph}{4}%
  {\z@}{0.75ex \@plus 1ex \@minus .2ex}{-1em}%
  {\normalfont\normalsize\bfseries}%
}
\makeatother

\def\SLP{\mbox{\rm {\sf SLP}}}
\def\rank{\mbox{\rm {\sf rank}}}
\def\lcs{\mbox{\rm {\sf lcs}}}
\def\lcp{\mbox{\rm {\sf lcp}}}
\def\lce{\mbox{\rm {\sf lce}}}
\def\LCE{\mbox{\rm {\sf LCE}}}
\def\ROT{\mbox{\rm {\sf ROT}}}
\def\select{\mbox{\rm {\sf select}}}
\def\col{\mbox{\rm {\sf col}}}
\def\NULL{\mbox{\rm {\sf null}}}
\def\len{\mbox{\rm {\sf len}}}
\def\pos{\mbox{\rm {\sf pos}}}
\def\row{\mbox{\rm {\sf row}}}
\def\LF{\mbox{\rm {\sf LF}}}
\def\FL{\mbox{\rm {\sf FL}}}
\def\W{\mbox{\rm {\sf w}}}
\def\A{\mbox{\rm {\sf A}}}
\def\A{\mbox{\rm {\sf A}}}
\def\SA{\mbox{\rm {\sf SA}}}
\def\LCP{\mbox{\rm {\sf LCP}}}
\def\ISA{\mbox{\rm {\sf ISA}}}
\def\IISA{\mbox{\rm {\sf (I)SA}}}

\def\PLCP{\mbox{\rm {\sf PLCP}}}
\def\PPLCP{\mbox{\rm {\sf (P)PLCP}}}
\def\RLCP{\mbox{\rm {\sf RLCP}}}
\def\RLBWT{\mbox{\rm {\sf RLBWT}}}
\def\MEM{\mbox{\rm {\sf MEM}}}
\def\KMEM{\mbox{\rm {\sf K-MEM}}}
\def\KSMEM{\mbox{\rm {\sf K-SMEM}}}
\def\MS{\mbox{\rm {\sf MS}}}
\def\LCP{\mbox{\rm {\sf LCP}}}
\def\NSV{\mbox{\rm {\sf NSV}}}
\def\PSV{\mbox{\rm {\sf PSV}}}
\def\RMQ{\mbox{\rm {\sf RMQ}}}
\def\BWT{\mbox{\rm {\sf BWT}}}
\def\BWM{\mbox{\rm {\sf BWM}}}
\def\ITR{\mbox{\rm {\sf index\_to\_run}}}
\def\GS{\mbox{\rm {\sf get\_symbol}}}
\def\PBWT{\mbox{\rm {\sf PBWT}}}
\def\MPBWT{\mbox{\rm {\sf mPBWT}}}
\def\MRLPBWT{\mbox{\rm {\sf mRLPBWT}}}
\def\DPBWT{\mbox{\rm {\sf dPBWT}}}
\def\RLPBWT{\mbox{\rm {\sf RLPBWT}}}
\def\SMEM{\mbox{\rm {\sf SMEM}}}
\def\M{\mbox{\rm {\sf M}}}
\def\C{\mbox{\rm {\sf C}}}
\def\Occ{\mbox{\rm {\sf Occ}}}
\def\L{\mbox{\rm {\sf L}}}
\def\F{\mbox{\rm {\sf F}}}
\def\DA{\mbox{\rm {\sf DA}}}
\def\DM{\mbox{\rm {\sf DM}}}
\def\PA{\mbox{\rm {\sf PA}}}
\def\LCE{\mbox{\rm {\sf LCE}}}
\def\UP{\mbox{\rm {\sf update}}}
\def\lceb{\mbox{\rm {\sf lce\_bounded}}}
\def\RM{\mbox{\rm {\sf reverse\_map}}}


\begin{document}
\maketitle
\setlist{leftmargin = 2cm}
\noindent
\subsection*{Slide 1}
Buongiorno, sono Davide Cozzi e oggi presento la mia tesi dal titolo:
``Algoritmi per la trasformata di Burrows--Wheeler posizionale con
compressione run-length''
\subsection*{Slide 2}
Questa presentazione sarà così divisa:
\begin{itemize}
  \item si vedrà una prima introduzione alla tematica della $\PBWT$ e del
  run-length encoding, al fine di poter comprendere al meglio gli scopi di
  questa tesi
  \item si vedranno poi i contributi in termini di strutture dati e algoritmi
  \item si vedranno poi i risultati sperimentali sui dati del 1000 Genome
  Project
  \item infine si chiuderà questa presentazione con qualche conclusione e con un
  breve excursus sugli sviluppi futuri di questo progetto
\end{itemize}
\subsection*{Slide 3.1}
Negli ultimi anni si è assistito a un cambio di paradigma nel campo della
bioinformatica, ovvero il passaggio dallo studio della sequenza lineare di un
singolo genoma a quello di un insieme di genomi, provenienti da un gran numero
di individui, al fine di poter considerare anche le varianti geniche. Questo
nuovo concetto è stato introdotto da Tettelin, nel 2005, con il termine di
pangenoma. Grazie ai risultati ottenuti in pangenomica, ci sono stati
miglioramenti sia nel campo della biologia che in quello della medicina
personalizzata, grazie al fatto che, con il pangenoma, si migliora la precisione
della rappresentazione di multipli genomi e delle loro differenze.
{\color{gray}Il genoma
umano di riferimento (GRCh38.p14), è composto da circa 3.1 miliardi di basi, con
più di 88 milioni varianti tra i genomi sequenziati, secondo i risultati
ottenuti nel 1000 Genome Project. Considerando che, grazie al miglioramento
delle tecnologie di sequenziamento, la quantità dei dati di sequenziamento sia
destinata ad aumentare esponenzialmente nei prossimi anni, risulta necessaria la
costruzione di algoritmi e strutture dati eﬀicienti per gestire una tale mole di
dati.}
Si hanno varie rappresentazioni possibili del pangenoma in termini di strutture
dati. In primis abbiamo la concatenazione diretta di multipli genomi. Una
soluzione più rappresentativa ed efficacie è tramite grafo, dove si da un ovvio
peso alle variazioni tra i vari genomi (che condividono circa il 99\% del codice
genetico).
Uno degli approcci più usati per rappresentare il
pangenoma è attraverso un pannello di aplotipi, ovvero, da un punto di vista
computazionale, una matrice di M righe, corrispondenti agli individui, e N
colonne, corrispondenti ai siti con le varianti. Si specifica che, con il
termine aplotipo, si intende l'insieme di alleli, ovvero di varianti che, a meno
di mutazioni, un organismo eredita da ogni genitore.
In questo contesto trova spazio uno dei problemi fondamentali della
bioinformatica, ovvero quello del pattern matching, che sui pannelli di aplotipi
sarà in questa tesi il calcolo dei set-maximal exact match. {\color{gray}
  Inizialmente 
  tale problema 
  era relativo alla ricerca di una stringa (pattern) all'interno di un testo di
  grandi dimensioni, cioè il genoma di riferimento. Ora, con l'introduzione del
  pangenoma, il problema deve essere risolto sulle nuove strutture di
  rappresentazione del pangenoma.}
\subsection*{Slide 3.2}
Possiamo qui vedere un pannello di aplotipi con 20 sample/aplotipi e 15 siti con
le varianti. In basso possiamo notare l'aplotipo query, ovvero il pattern, che
presenta esattamente il numero di siti del pannello, avendo che ogni
sito è esattamente lo stesso sito sul pattern. Da questo deriva il termine
``posizionale'' della $\PBWT$.\\
In blu possiamo notare cosa si intende con $\SMEM$, ovvero match massimali
esatti tra una o più sottosequenze di aplotipi del pannello e una sottosequenza
del pattern.\\
Si noti che si trattano pannelli costruiti su un alfabeto binario, a causa del
fatto che la natura diploide dell'uomo comporta siti biallelici, anche se
diversi studi segnalano una presenza stimata di 3/6\% di siti triallelici (per
uno SNP o anche per una delezione di una base).
\subsection*{Slide 4.1}
Una delle strutture dati più utilizzata per la rappresentazione del pangenoma è
la trasformata di Burrows–Wheeler Posizionale (PBWT), presentata da Richard
Durbin nel 2014.
Il funzionamento della PBWT prevede la costruzione di due insiemi di array,
tramite l’ordinamento dei prefissi inversi a ogni colonna del pannello, detti
insieme dei prefix array (che tiene traccia degli indici degli ordinamenti) e
insieme dei divergence array (che tiene traccia della colonna d'inizio del
prefisso inverso più lungo tra una riga e la precedente nel riordinamento ad una
certa colonna). Il pannello, permutato  
tramite l’insieme degli $a_k$ (che considerano l'ordinamento inverso fino
alla colonna $k-1$ e), è detto matrice PBWT.\\
La $\PBWT$, a causa della natura biologica del dato, avendo che il pannello è
formato da aplotipi che tendono ad essere molto simili, tende a produrre nella
matrice $\PBWT$ lunghe sequenze continue del medesimo carattere. Questo in
quanto aplotipi simili fino alla colonna $k-1$ è molto probabile proseguano in
colonna $k$ col medesimo carattere.\\
Risulta quindi interessante il paradigma del run-length encoding, che consiste
nel memorizzare le run, ovvero sequenze massimali di caratteri uguali, in modo
compatto, come coppia (carattere, lunghezza). Il punto fondamentale sarà rendere
gli algoritmi che ora sono lineari sul numero di sample, ad essere
sublineari sullo stesso, essendo lineari sul numero di run.\\
Possiamo qui vedere un semplice esempio con 000000 memorizzato come (0,6).
\subsection*{Slide 4.2}
Qui, ad esempio, vediamo la costruzione della trasformata alla colonna 6, basata
sul riordinamento fino alla quinta, e la conseguente produzione dei due array.
Il prefix array tiene traccia degli indici riordinati, come visibile nella prima
colonna dedicata agli indici mentre il divergence array della colonna d'inizio
del prefisso inverso comune più lungo tra due sottosequenze consecutive nel
riordinamento.  
Si noti che il divergence può anche essere sostituito dal Reverse Longest Common
prefix, che memorizza la lunghezza del prefisso comune.
% Lo scopo di questa tesi è progettare strutture dati e algoritmi eﬀicienti per
% risolvere il problema del pattern matching, inteso come ricerca dei set-maximal
% exact match (SMEM) tra un aplotipo esterno e un pannello di aplotipi, in una
% delle strutture dati più utilizzata per la rappresentazione del pangenoma: la
% trasformata di Burrows–Wheeler Posizionale (PBWT).\\
% {\color{gray}Questo progetto, svolto in collaborazione con il laboratorio BIAS e
% con diversi ricercatori internazionali (University of Florida, Dalhousie
% University e Tokyo Medical and Dental University), permetterà la gestione e lo
% studio (ad esempio nei GWAS) dei
% sempre più grandi dati provenienti dalle tecnologie di sequenziamento. Inoltre,
% con tale progetto, si è confermata l'ovvia correlazione tra la BWT e la PBWT,
% estendendo tale correlazione anche alle rispettive varianti run-length.}
\subsection*{Slide 5}
Il problema del calcolo degli $\SMEM$ presenta una soluzione semplice
in $\mathcal{O}(N^2M)$, avendo che normalmente $N>>M$. Un tempo di calcolo
assolutamente non permettente alcun tipo di analisi.\\
La PBWT permette di calcolare gli SMEM, di cui un esempio è qui disponibile,
tra un aplotipo esterno e il pannello in tempo Avg. $\mathcal{O}(N + c)$ (dove c
è il numero complessivo di SMEM), tramite il famoso algoritmo 5 di Durbin che si
basa sul 
mantenere ed eventualmente estendere un intervallo sui prefix array che contiene
gli indici delle righe che hanno uno SMEM fino a quella colonna. Se l'intervallo
non è più estendibile si reporta lo SMEM e si sfrutta il divergence array per
computare il nuovo intervallo.
Il tradeoff di questo algoritmo è la richiesta in termini di spazio (13NM
bytes), dovuto ad ulteriori array necessari in memoria per il ``mapping'',
ovvero il forward step, tra una colonna e la successiva nella matrice
$\PBWT$ (non computabili di volta in volta considerando di poter avere più
query). Superare questo limite è l’obiettivo principale di questo progetto di 
tesi, presentando una PBWT run-length encoding in grado di computare gli SMEM in
modo efficiente, dal punto di vista dello spazio. L'uso del run-length encoding
potrebbe permettere una forte riduzione di 
memoria. 
\subsection*{Slide 6}
Si ha qui una breve panoramica delle componenti atomiche che hanno permesso la
creazione delle varianti della RLPBWT:
\begin{itemize}
  \item componenti per il mapping tra una colonna e la successiva nella
  $\PBWT$, tramite bitvector sparsi (\texttt{MAP-BV}) o intvector compressi
  (\texttt{MAP-INT}). Tali componenti includono tutte le informazioni necessarie
  al mapping tra una colonna e la successiva, memorizzando l'indice di ogni run
  e gli 
  equivalenti dell'FM-index. Inoltre si memorizza un singolo bool per poter
  risalire la carattere di ogni singola run
  \item componenti per le threshold (\texttt{THR-BV}/\texttt{THR-INT}), dove si
  memorizza l'indice ogni threshold, ovvero il primo valore minimo dell'array
  RLCP 
  \item componente per i prefix array sample (\texttt{PERM}), ovvero i valori di
  prefix array ad inizio e fine di ogni run
  \item componenti per il random access, tramite pannello di bitvector
  (\texttt{RA-BV}) tramite $\SLP$ (\texttt{RA-SLP})
  \item componente per le $\LCE$ query con $\SLP$ (\texttt{LCE})
  \item componente per il calcolo delle funzioni $\varphi$ e $\varphi^{-1}$
  (\texttt{PHI}), che permettono data una colonna e un valore di prefix array,
  di sapere quale sia il valore precedente e quello successivo
  \item componente per il reverse longest common prefix (\texttt{RLCP}), che non
  scala sul numero di run
\end{itemize}
Il senso di queste multiple componenti si ritrova nel fatto che, parlando di
strutture dati succinte e compresse, è difficile stimare l'effettivo spazio
necessario basandosi solo sulle complessità asintotiche. Inoltre, dal punto di
vista temporale, si aggiunge il problema che gli algoritmi tratti dipendono
fortemente dalla caratteristica del dato. Al fine di esplorare a pieno le varie
soluzioni quindi, oltre ad aver studiato e implementato le varianti di MONI e
PHONI, si sono studiati gli usi di varie strutture dati sottostanti.\\
Si possono fare dei confronti tra le componenti con
multiple rappresentazioni in termini di complessità temporale. Avendo che
$M>>\rho$ si nota come gli intvector compressi si preannunciano più veloci.
Si nota inoltre come il random access (o il calcolo delle $\LCE$ query), per
quanto tale caso peggiore sia irrealistico nel nostro caso dovendosi in realtà
basare sulla stringa prodotta dall'SLP, sia nettamente meno performante con tale
grammatica compressa.
\subsection*{Slide 7}
Possiamo qui confrontare velocemente a sinistra le stime di memoria dell'uso di
un bitvector sparso e un intvector compressso, stime derivanti dai dati di SDSL
(la lib usata) e dal numero di run attese (proporzionale a quanto visto con i
dati del 1000 genome project). Si nota quindi che, per quanto all'inizio gli
intvector compressi richiedano meno memoria tale comportamento è destinato ad
invertirsi all'aumentare del numero di sample (assumendo la proporzionalità
sperimentale tra M e $\rho$).
\subsection*{Slide 8.1}
Per il calcolo degli SMEM si hanno due possibili soluzioni:
\begin{enumerate}
  \item usare una variante dell'algoritmo di Durbin che però necessita del RLCP
  non proporzionale al numero di run, per le informazioni memorizzate. Inoltre
  non si è trovato un modo per 
  calcolare quali righe presentassero uno SMEM ma solo quante.
\end{enumerate}
Un'altra soluzione è usare l'array delle matching statistics
\begin{definizione}
  Dato un pannello $X$, di dimensioni $M\times N$, con $M$ individui e $N$ siti,
  e un aplotipo esterno/pattern $z$, tale che $|z|=N$, si definisce matching
  statistics di $z$ su $X$ un array $\MS$ di coppie $(\row,\len)$, di lunghezza
  $N$, tale che (avendo che $x_i$ indica l'$i$-esima riga del pannello $X$): 
  \begin{itemize}
    \item $x_{\MS[i].\row}[i-\MS[i].\len+1,i]=z[i-\MS[i].\len+1,i]$, ovvero si
    ha che 
    l'aplotipo query ha un match, terminante in colonna $i$, con la riga
    $\MS[i].\row$  
    \item $z[i-\MS[i].\len,i]$ non è un suffisso terminante in colonna $i$ di un
    qualsiasi sottoinsieme di righe di $X$. In altri termini, il match non deve
    essere ulteriormente estendibile a sinistra
  \end{itemize}
\end{definizione}
Tale soluzione permette il completo calcolo degli SMEM.
\begin{lemma}
  Dato un pannello $X$, di dimensioni $M\times N$, con $M$ individui e $N$
  siti, un aplotipo esterno/pattern $z$, tale che $|z|=N$, e il corrispondente
  array di matching statistics $\MS$ si ha che $z[i-l+1,i]$
  presenta uno $\SMEM$ di lunghezza $l$ in con la riga $\MS[i].\row$ del
  pannello $X$ sse: 
  \[\MS[i].\len=l\land(i=N-1\lor \MS[i].\len\geq \MS[i+1].\len)\]
\end{lemma}
\subsection*{Slide 8.2}
A sua volta l'array MS può essere calcolato in due modi, ispirati da precedenti
risultati ottenuti per la RLBWT:
\begin{enumerate}
  \item usare le threshold per computare le righe e il random access per
  computare le lunghezze, come in MONI in due passaggi
  \item usare le LCE query per computare entrambi in un solo passaggio, come in
  PHONI 
\end{enumerate}
\subsection*{Slide 9}
Si ha quindi lo schema che mostra le 8 strutture dati studiate. Di fatto le
soluzioni sono 3, che diventano 8 per il discorso di dualità visto
precedentemente.
Si hanno quindi:
\begin{enumerate}
  \item le strutture che vediamo in centro, basate sul rifacimento
  dell'algoritmo 5 di Durbin e sull'uso dell'RLCP. Non è in grado di sapere
  quali siano le righe che presentano un certo SMEM ma solo quante
  \item le soluzioni ispirate a MONI
  \item le soluzioni ispirate a PHONI
\end{enumerate}
Le ultime due soluzioni computano esattamente quali righe presentano uno SMEM.\\
È superfluo notare come le prime due soluzioni non siano effettivamente
utilizzabili ma sono state citate in quanto punto iniziale di questa tesi e dei
primi studi sull'uso del run-length.
\subsection*{Slide 10}
In questa slide possiamo visualizzare un semplice esempio di matching statistics
con la PBWT, con i avlori per le righe e per le lunghezze.
Ad esempio, con $k=5$, abbiamo $\row=13$ e $\len=6$, infatti con la riga 6 si ha
un suffisso comune lungo 6, terminante in $k=5$, con la riga 13.
\subsection*{Slide 11}
Possiamo qui vedere, ad alto livello, come funzioni la struttura per il calcolo
delle funzioni $\varphi$ che permettono, dato un valore di prefix array e una
colonna, di computare il valore di prefix array precedente e quello
successivo. Il computo si basa sull'uso dei prefix array sample ed eventualmente
dell'ultimo prefix array considerando quando due linee consecutive si separano
durante le permutazioni. Quando si separano sono sicuramente una fine di run e
una testa di run e quindi si può sapere che fino a quella colonna sono
consecutive. Si tiene traccia quindi tramite bitvector di dove una riga sia
testa o coda di run e tramite intvector compresso dell'indice della riga sopra e
sotto. L'ultimo prefix array serve per quelle righe che non si ``spezzano'' mai.
Quindi si cerca in su e in giù a partire dallo SMEM di MS fino a che si ha il
medesimo SMEM (avendo che sono tutti consecutivi nel riordinamento in una certa
colonna)
\subsection*{Slide 12}
La sperimentazione, orchestrata tramite \texttt{snakemake}, è stata
effettuata su una macchina con processore 
Intel Xeon E5-2640 V4 ($2,40$GHz), $756$GB di RAM, $768$GB di swap e
sistema operativo Ubuntu 20.04.4 LTS.\\
Si sono confrontate l'implementazione in C++ della $\RLPBWT$ e
l'implementazione in C ufficiale della $\PBWT$.\\
Si segnala che la RLPBWT supporta lo studio multithread di stringhe ma è stato
usato un singolo thread per questi test a fini di avere risultati più
comparabili.\\
Vediamo qui le caratteristiche dei pannelli usati, relativi alla phase 3 del
1000 Genome Project. Si nota come il numero di run sia molto inferiore
all'altezza del pannello, fattore che conferma l'utilità del run-length
encoding.
\subsection*{Slide 13}
Si iniziano a vedere i risultati sperimentali.\\
In primis possiamo studiare i tempi di costruzione delle varie strutture anche
se bisogna specificare che:
\begin{itemize}
  \item nel caso della $\RLPBWT$, per ognuna delle strutture dati
  composte, questa fase prevede la costruzione e la 
  serializzazione dell'intera struttura dati
  \item nel caso della $\PBWT$, questa fase crea unicamente un file
  compresso ad hoc, contenente le strutture base delle $\PBWT$. A partire
  da tale file, in fase di calcolo degli $\SMEM$, verranno calcolati anche
  tutti gli altri indici necessari al calcolo degli stessi, a seconda
  dell'algoritmo usato 
\end{itemize}
Si confermano quindi i risultati attesi:
\begin{itemize}
  \item usare il RLCP richiede più memoria
  \item l'uso dei bitvector richiede più memoria ma anche più tempo di
  costruzione (dovendo costruire le strutture per $\rank$ e $\select$)
\end{itemize}
\subsection*{Slide 14}
I risultati in termini di spazio richiesto dalle singole componenti della RLPBWT
possono anche essere qui confermati, avendo appunto rappresentato il peso in
mega di ognuna di esse:
\begin{itemize}
  \item l'uso degli intvector è estremamente vantaggioso
  \item l'uso dell'SLP richiede pochissima memoria rispetto alla corrispondente
  con bitvector
\end{itemize}
\subsection*{Slide 15}
Si confrontano ora i tempi di calcolo degli SMEM su 10'0 query. Parlando di PBWT
si ha che matchIndexed è l'algoritmo 5 mentre si segnala
che Durbin ha proposto anche un algoritmo per il calcolo degli SMEM tra un
pannello di  aplotipi e uno di query. Questo algoritmo è basato sulla creazione
“virtuale” di un unico pannello, su cui costruire la PBWT, e sul calcolo dei
match interni al pannello stesso, tale algoritmo è detto matchDynamic. Pur non
essendo lo scopo della tesi studiare pannelli di query è sembrato corretto
considerare tale soluzione.\\
I risultati sono evidenti:
\begin{itemize}
  \item matchDynamic risulta essere il migliore sia in spazio (avendo che
  computa dinamicamente tutti gli indici dovendo farlo una sola volta per tutte
  le query) che in tempo
  \item si confermano i limiti spaziali dell'algoritmo 5 di Durbin
  \item si conferma l'uso in tempo e spazio degli intvector sui bitvector
  \item si conferma quanto detto in merito al random access
\end{itemize}
\textbf{Aggiunegre qualche numero}
\subsection*{Slide 16}
Interessante è stato però confrontare i tempi su una singola query, calcolando
media e deviazione standard su 100 query.\\
Si noti una cosa interessante: mathcDynamic ha quasi le stesse prestazioni su 1
query che su 100. Questo, aggiungendosi al fatto che i risultati non sono
ordinati per query ma per permutazione, rappresenta un limite di tale algoritmo,
ad esempio in ottica di uso tramite portale web (come per BLAST ora). Se per
ogni query si carica e scarica diventa inefficiente. \\
In merito a tutte le altre soluzioni si conferma quanto già detto.\\
\textbf{Aggiunegre qualche numero}
\subsection*{Slide 17}
Concludendo questa presentazione si segnala la potenzialità dei risultati run
length encoded, confermando quanto già visto con la BWT classica. Inoltre
l'obiettivo della tesi è stato pienamente raggiunto, come confermato dalla
sezione risultati.\\
Ovviamente c'è spazio per molti sviluppi futuri:
\begin{itemize}
  \item ottimizzazioni per pannelli di query, per mettere un avvicinamento ai
  risultati visti con matchDynamic
  \item $\SMEM$ interni con $\RLPBWT$, per completare il quadro degli algoritmi
  di Durbin
  \item $\RLPBWT$ con dati mancanti, una tematica in forte studio in
  bioinformatica in quanto, causa errori nelle macchine di sequenziamento, ci
  sono siti per cui non si ha informazione. Studi in tal senso potrebbero
  portare ad una maggior potenza di imputazione
  \item $\RLPBWT$ multiallelica, per il discorso dei siti triallelici umani e
  per estendere lo studio, in futuro, anche ad altre specie (le piante sono
  fortemente poliploidi)
  \item calcolo $\KSMEM$ con $\RLPBWT$, ovvero SMEM con esattamente $k$ righe,
  al fine di sperimentare la risoluzione di nuovi task utili a studi statistici
\end{itemize}
\subsection*{Slide 18}
Per ulteriori dettagli e per altre strutture dati compresse sviluppate in ottica
PBWT si rimanda al preprint del paper del quale sono autore.
Questo progetto, infatti, è stato svolto in collaborazione con il laboratorio
BIAS e 
con diversi ricercatori internazionali (University of Florida Boucher-Rossi,
Dalhousie 
University Gagie-Kashgouli e Tokyo Medical and Dental University K\"{o}ppl).\\
Grazie a tutti per l'attenzione
\end{document}


% LocalWords:  pangenoma naive sottostringa BWT sottostringhe Durbin prefix MEM
% LocalWords:  array matching threshold divergence PBWT SMEM query statistics
% LocalWords:  RLBWT aplotipi aplotipo Burrows Wheeler RLPBWT maximal exact LCP
% LocalWords:  LCE
